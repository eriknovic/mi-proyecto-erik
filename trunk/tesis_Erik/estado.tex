\chapter{Estado del arte}
\label{cap:soa}

\section{Integración semántica de recursos de información}
User Interests Clustering for E-government Information  Resources Integration

Este artículo aborda la integración de los recursos de información de gobierno electrónico basados en la agrupación intereses de los usuarios, y a continuación, llevar a cabo el estudio empírico del gobierno de la Provincia de Hubei del portal página web con la tecnología de clasificación automática y la tecnología de agrupación automática

Con la creciente popularidad del gobierno electrónico (correo electrónico) la gente puede tener acceso a abundantes servicio de información poco a poco, y disfrutar de la más eficiente y de alta calidad de servicios públicos de la información  por medio de una avanzada tecnología.
Sin embargo, desde la situación actual de los recursos de información de e-gobierno, hay algunos problemas ampliamente existentes, como el intercambio de información bloqueada, la duplicación de los recursos de información, la falta de unificación y planificación y el control efectivo en la construcción y administración de recursos, que han creado obstáculos para la realización de recursos compartidos en cada tipo de sistemas de gobierno.

Por medio de la aplicación de tecnologías de auto-clustering y auto clasificación, esta investigación tiene como objetivo orientar de una manera más razonable  la clasificación, organización, almacenamientos , distribución e integración del gobierno de los recursos de información  . 

En otras palabras lo que se pretende  es mejorar la utilización de administración  (gobierno) de recursos  y mejorar la eficiencia de la gestión de la información
El resultado que muestra este nuevo método puede eficientemente resolver la  contradicción entre dispersos  gobierno de información y la de los usuarios, la demanda global de la información  que promete ser más  individual, orientada a las necesidades

LAWYER INFORMATION INTEGRATION AND RECOMMENDATION 

En internet  todo tipo de información se encuentra  en fuentes de información separadas lo que impide que los usuarios  adquieran información de una manera eficaz. En el orden de construir una visión unificada de separación de información ,heterogeneidad y redundante información. 

Heterogeneous  Information  Integration  and Management  Models in  Thai Justice  Information  Systems
Los problemas críticos son comunes como  la duplicación de datos y la inconsistencia de datos
Como resultado, cualquier intento de integración de la información causa la duplicación de datos y problemas de inconsistencia de datos.
Sin embargo, estos problemas pueden ser teóricamente resuelto mediante el uso de identificador único global, tales como cédula de ciudadanía número identificador o atributos comunes que están disponibles en fuentes locales.
En la práctica, sólo utilizando el identificador único global puede no ser suficiente. Hace falta un Modelo de asignación y limpieza de datos aún se encuentran en necesidad.
El objetivo principal de este trabajo es proponer un combinación del modelo de integración de la información y la modelo de gestión que se puede realizar con éxito integración de la información para el gobierno tailandés

este trabajo propone la técnica de integración de información denominado modelo  DXC-QM que puede lleva a cabo la integración de información de fuentes heterogéneas de información distribuida. El modelo de integración se basa en el modelo de mediador con la arquitectura de servicios de recursos (ROA)
La técnica propuesta es capaz de superar los problemas de los diferentes sistemas de información , de diferentes formatos de datos estándar, las infraestructuras de diferentes sistemas y diferentes políticas de gestión de la información. Sin embargo problemas no técnicos, como cuestión de derecho y la protección de la privacidad no puede ser garantizados mediante el uso de sólo el modelo de integración de datos. El modelo de información de gestión adecuada es, por tanto, crítico y se describe en este trabajo. El modelo de gestión propuesto puede apoyar el modelo de integración, así como para resolver todos los problemas no técnicos que se discutieron anteriormente.

Los modelos propuestos son capaces de superar los problemas de los sistemas de información diferentes, diferentes formatos de datos estándar, las infraestructuras de diferentes sistemas y diferentes políticas de gestión de la información. El modelo de gestión ayuda a promover la transparencia, la rendición de cuentas y capacidad de auditoría de los sistemas de información en la justicia tailandesa.

%fuentes C:\Users\Gatito\Dropbox\Gestión Semántica\Actividades 12P\Semana 10\antecedentes.docx

Archetype-Based Semantic Integration and Standardization of Clinical Data
Resumen-Una de las necesidades básicas para cualquier profesional de la salud es poder acceder a la información clínica de los pacientes de una manera comprensible y normalizada. La información clínica de toda la vida de cualquier persona que cuente con los medios electrónicos configura su / su Historia Clínica Electrónica (HCE). Esta información se distribuye generalmente entre varios sistemas independientes y heterogéneas que pueden ser sintácticamente y semánticamente incompatibles. La arquitectura Dual Modelo ha aparecido como una nueva propuesta de mantener una representación homogénea de la HCE con una clara separación entre la información y el conocimiento. La información se representa mediante un modelo de referencia que describe estructuras de datos comunes con la semántica mínimos. El conocimiento es especificado por arquetipos, que son representaciones formales de conceptos clínicos gracias a una modelo de referencia particular. Este tipo de arquitectura se pensó originalmente para la implantación de nuevos sistemas de información clínica, pero arquetipos puede también ser utilizado para la integración de datos de los sistemas existentes y no normalizada, añadiendo al mismo tiempo un significado semántico de los datos integrados. En este artículo se explica el posible uso de un enfoque dual modelo de integración semántica y normalización de fuentes heterogéneas de datos clínicos y presentar LinkEHR-Ed, una herramienta para el desarrollo de arquetipos como elementos para los propósitos de integración. LinkEHR-Ed se ha diseñado para ser utilizado fácilmente por los dos participantes principales del proceso de creación de arquetipos para la integración de datos clínicos: el experto de dominio de la Salud y las Tecnologías de la Información del dominio experto.

CONCLUSIÓN
Posiblemente, un enfoque Arquitectura Modelo Dual es hoy en día una de las mejores opciones para la construcción de nuevo sistema de información clínica debido a su capacidad para el intercambio de información clínica. Arquetipos nos dan una capa semántica para el entendimiento común y la mutua comunicación de los datos clínicos estructurados como una definición de concepto clínico formal incoado por expertos en los sectores de salud, logrando al mismo tiempo una interoperabilidad semántica automática entre los sistemas de información clínicos. Pero los arquetipos son también un enfoque válido para actualizar sistemas ya implementados con el fin de hacerlos compatibles con las normas EHR, teniendo en cuenta los arquetipos como componentes de integración de datos clínicos. El beneficio de este enfoque es la de mantener en sistemas de producción y aplicaciones sin cambios mientras que proporciona un medio para la extracción de información clínica a partir de esos sistemas en la forma de extractos estandarizados de HME, ocultando detalles técnicos, la ubicación y la heterogeneidad de los repositorios de datos. Al mismo tiempo, constituyen una capa semántica sobre las bases de datos subyacentes que los asocian con la semántica de dominio específico. Por lo tanto, es posible combinar de una manera fácil la representación formal de los conocimientos de un experto en dominio de la Salud, representado por un arquetipo, con la información de asignación para las fuentes de datos donde se almacenan los datos clínicos y utilizarlos juntos para propósitos de estandarización y la integración semántica.

A Semantic Integration Solution for Online Accommodation Information Integration
Con el tremendo crecimiento de la Web, un amplio espectro de información de alojamiento está disponible en Internet. Con el fin de apoyar adecuadamente a los usuarios de información en línea para reunir y compartir información relacionada con el alojamiento, es importante para crear una solución efectiva integración de la información. Enfoques de integración de datos existentes, como el enfoque wrappermediator proporcionan soluciones genéricas para la integración de información en línea. Sin embargo, las soluciones desarrolladas se centran principalmente en la integración de información a pequeña escala, donde las fuentes de datos integrados no están cambiando constantemente. Por lo tanto, no pueden satisfacer las necesidades de la naturaleza amplia, dinámica y heterogénea del dominio de alojamiento en linea. En este trabajo, examinamos las capacidades de las soluciones actuales para la integración de la información en línea en el dominio de alojamiento, y propone un enfoque de integración semántica basada en ontologías mediante la utilización de los beneficios de las soluciones tradicionales de integración. El enfoque propuesto tiene como objetivo proporcionar una solución eficaz, flexible y escalable para la integración de la información a gran escala

CONCLUSIÓN
En este trabajo se propone un marco de integración semántica para la integración de información en línea. El marco propuesto tiene una serie de características únicas. (1.) Para hacer frente al problema de la heterogeneidad de datos, hemos utilizado la ontología como mediador para facilitar el acceso de información integrado. Locales esquemas de origen de datos se asignan a un esquema ontología compartida para permitir la transformación automática de datos. (2.) Para resolver la naturaleza dinámica de las fuentes de información integrados, hemos introducido una publicación combinar de usar el proceso de integración.

El procedimiento propuesto permite a los propietarios de la información para participar en el proceso de integración, y para ayudar a identificar y gestionar los cambios ocurridos en el lado de la fuente. (3.) Además, para evitar la aplicación de un único esquema de integración de la información, que combinan el enfoque LaV con el enfoque distribuido, el enfoque combinado utiliza una serie de pequeños esquemas de intercambio de información. Dado que el objetivo principal de la solución de integración propuesto es permitir la integración de información a gran escala, los futuros trabajos de investigación pueden llevar a cabo para probar la solución en un pequeño entorno de integración de información de escala.

Using Ontology and XML for Semantic Integration of Electricity Information Systems
Hoy en día, la integración semántica de los sistemas de información se está convirtiendo en un tema candente. Sistemas de información de la electricidad son el sistema heterogéneo con hay una creciente comprensión DE XML como un organizaciones y funciones descentralizadas. Como medio para el intercambio de datos, este documento se centra en la integración semántica basada en ontologías utilizando la tecnología XML para los sistemas de información de la electricidad. En primer lugar, hablamos de heterogeneidades semánticas en los documentos XML de datos de electricidad y describir cómo las ontologías pueden utilizarse para superar los problemas relacionados. A continuación se propone la arquitectura para la integración semántica, incluyendo tres capas principales: datos distribuidos heterogéneos fuentes capa, la capa de integración de información y sistemas de capa de aplicación. Se discute el enfoque de la integración semántica de documentos XML, que se aplica en la arquitectura. Al final llegamos a la conclusión de que la ontología es una buena herramienta para integrar la información de la electricidad a nivel semántico.

XML ha sido el estándar de facto de intercambio de datos en Internet. Sin embargo, no se puede expresar totalmente la información semántica a menos que todos los miembros comparten los mismos conjuntos de etiquetas comunes. Cómo integrar conjuntos de datos XML heterogéneas a nivel conceptual se ha convertido en uno de los mayores problemas en la investigación actual sobre la web semántica. Ontología proporciona una especificación común formal de conceptos de dominio específico, y este conocimiento es independiente de cualquier representación. Por lo tanto ontologías están capacitados para expresar la información semántica a nivel conceptual. Sistemas de información de la electricidad son el sistema heterogéneo con una organización descentralizada, la función descentralizada y modelos complejos. En el entorno web, la integración entre los sistemas de información de energía eléctrica se desarrolla hacia la integración semántica. La arquitectura para la integración semántica utiliza términos estandarizados de la ontología y su semántica inherente para proporcionar una descripción formal de sus datos. Consultas basadas en la semántica uniformes son menos propensos a la mala interpretación de la semántica de información locales. Usando los términos de la ontología como meta-construcciones o meta-atributos permite interpretación dinámica adecuada de los diferentes contextos. Nuestras futuras investigaciones ponen sobre los siguientes aspectos: la integración automática entre diferentes ontologías de dominio de poder y la representación e inferencia de ontología de dominio poder bajo el entorno grid.

DESIGN RATIONALE AS PART OF CORPORATE TECHNICAL MEMORY
En la era de la economía basada en el conocimiento y la personalización en masa, el conocimiento ha sido considerado como un factor estratégico para conseguir ventajas en competencia. Así, la gestión del conocimiento ha atraído la atención de las empresas y la academia. La memoria de las empresas es el sistema informático de apoyo a las actividades de gestión del conocimiento de la empresa (identificación, adquisición, almacenamiento, uso, comunicación y desarrollo). Justificación Design es un tipo de conocimiento que afecta a la competencia central de las empresas manufactureras. Esto explica por qué y cómo se diseña un producto tal como es. Justificación diseño puede ser utilizado para apoyar la reutilización de diseños, comunicación diseño y verificación del diseño. Por lo tanto la calidad y la eficiencia del diseño se pueden mejorar. En este trabajo, la captura y la disponibilidad de los fundamentos del diseño han sido tratados como parte de las actividades de gestión del conocimiento. Adoptamos un enfoque basado en ontologías para capturar la información lógica de diseño y proporcionar thsm activamente con un agente inteligente integrado con el sistema de gestión de flujo de trabajo. Las ontologías para el diseño de modelos justificación se describen y la metodología de captura y establecer el fundamento de diseño activa se presenta bajo el fondo del diseño de automóviles de carga.

Conclusiones Diseño racional es un componente importante de las competencias básicas de las empresas manufactureras. En este trabajo se lleva a razón de diseño como parte de la Memoria técnica de las empresas. Al describir diseño de la información con fundamento homogénea ontologías, ingeniería heterogénea las fuentes de información se puede acceder de manera uniforme. Justificación diseño puede ser capturado de manera activa y proporcionado mediante la ampliación de la funcionalidad de diseño procesar sistema de apoyo y un agente inteligente. Este enfoque basado en ontologías supera cuellos de botella de adquisición de conocimientos de diseño construcción del sistema de justificación.

Building corporate memories in collaborative way using ontologies
La tarea de la Gestión del Conocimiento (KM) es capturar el conocimiento explícito y tácito de una organización con el fin de facilitar el acceso, el intercambio y la reutilización de esa información. Capital de conocimiento es un activo estratégico en el logro de los objetivos, un elemento importante para la supervivencia de la organización. En este artículo, se presenta la importancia de contar con un entorno de colaboración para la gestión de memorias corporativas. Primero Vamos a mostrar el interés de utilizar memorias empresariales para gestionar el conocimiento y / o documentos. En segundo lugar, vamos a proponer un modelo de interacción adecuada para representar y gestionar memorias corporativas en forma colaborativa. Por último, presentamos PCOGEME, un entorno de colaboración basado en ideas y consensual mecanismo de toma de construir memorias corporativas utilizando ontologías decisión.

En este artículo, hemos presentado PCOGEME, un entorno de colaboración para gestionar memorias corporativas basadas en ontologías. PCOGEME hace posible la creación, gestión, difusión, mantenimiento de memorias de empresa, respetando los roles de cada uno. Elso, se ha justificado el uso de la memoria corporativa y la contribución de las ontologías en este paso. Entonces nos mantuvimos en su conjunto de funcionalidades básicas que debe ofrecer un entorno para la gestión del conocimiento. ¿Cuál es el futuro de la investigación sobre la gestión del conocimiento? A pesar de que existen herramientas comercializadas por empresas industriales, muchos problemas siguen sin resolverse y mucha investigación todavía tiene que llevarse a cabo. Citemos las respuestas de las siguientes preguntas:
1)	Detección de necesidades: el uso de la encuesta de la tierra en los servicios y la organización de software.
2)	La construcción de la memoria corporativa: Edificio de colaboración de ontologías o de bases de conocimiento 
3)	Difusión y uso de la memoria corporativa: ontologyguided búsqueda de información, explotación de XML, 
4)	Evaluación de la memoria corporativa: métricas dedicados memoria corporativa,
5)	Evolución de la memoria corporativa: el conocimiento revisión base por actores organización.

Ontology-Based Semantic Integration for Cooperative Distributed Multidisciplinary Design Optimization Environments
Resumen - La reciente explosión de la nueva optimización de los conocimientos y la tecnología avanzada de equipo de diseño ha sentado las bases para los campos emergentes QF distribuido optimización del diseño multidisciplinar (MOO). Ahora, el reto que enfrentan los diseñadores es utilizar efectivamente esta gran cantidad de conocimientos. Hay muchas herramientas de software disponibles en cada área de diseño. Sin embargo, el problema clave es cómo integrar estas herramientas y bases de datos, que se ajustan a diferentes interfaces y requisitos con poca consideración a la integración y la reutilización, de forma flexible y robusto. En este trabajo se propone un marco de integración semántica basada en ontologías novela para entornos distribuidos MDO cooperativas. El aspecto de la integración semántica que sentará las bases para la arquitectura orientada a servicios para entornos distribuidos MDO. El aspecto de la cooperación se centrará en la integración perfecta entre los sistemas de MDO autónomas en un entorno abierto dinámico, utilizando paradigma multi-agente.

Conclusión?En este trabajo se presenta un proyecto en curso sobre la ontología / agente basado en entorno integrado MDO a cabo con una serie de tecnologías emergentes como la integración semántica basada en ontologías, agentes de software, Internet / Web y XML. Esta investigación estudia, desde una perspectiva fundamental y práctica, varias estrategias de integración y cooperación para desarrollar arquitecturas eficaces para entornos de MDO. Además, trata de diseñar y desarrollar sistemas con cualidades de rendimiento en términos de escalabilidad y robustez. El prototipo ha sido completado de los requisitos del sistema de definición para el diseño e implementación del sistema.

El trabajo principal incluye el modelado semántico basado en ontologías, la integración semántica, Web de usuario basada en interfaces de diseño e implementación, basada en el agente de gestión de recursos de computación o de equilibrio de carga y la gestión de datos basado en XML. Un prototipo está terminado y en proceso de validación. El trabajo futuro incluye la finalización de la ejecución de prototipos y validación a través de casos industriales. Las ventajas de esta arquitectura de integración semántico orientado a agentes ontología impulsada incluye: el problema de optimización del diseño multidisciplinar se presenta como una información general se reúnen problema, solución multiagente nos proporciona mecanismos para lidiar con el cambio de los datos, la aparición de nuevas fuentes, pensando en las características de servicios secundarios para los usuarios, y por supuesto lo obvio distribuidos logros de proceso de desarrollo paralelo, procesamiento concurrente, y la posibilidad de manejar cierta seguridad u otras cuestiones de organización. En el futuro, tenemos la intención de validar estos conceptos por los escenarios globales. Otras actividades se incluyen: primero, la atención se centrará en la eficacia del sistema propuesto para el cálculo distribuido MDO en entorno abierto dinámico, basado en el sistema de prototipo con la Internet y la web como medios de integración. En segundo lugar, la participación de más de ontologías para ampliar aún más la integración semántica hasta un nivel de integración de la ontología. Se propone la metodología de integración semántica y la arquitectura general del sistema no sólo para esta aplicación particular MDO, sino también para muchos otros dominios de aplicación similares, como las finanzas y la bioinformática, y muchos módulos de software (por ejemplo, la gestión de datos basada en XML, gestión de recursos de computación, etc ) puede ser reutilizado en otras aplicaciones incluso más.

\section{Herramientas para la integración semántica de recursos}
%%%Fuentes: C:\Users\Gatito\Dropbox\Gestión Semántica\Actividades 12P\Semana 8 y 9\Anotaciones Semánticas.docx

%%%C:\Users\ARTE\Dropbox\Gestión Semántica\Actividades 13I\feedback\CMED_8_FEB_Integracion Semántica de los recursos.docx

Las tecnologías semánticas son variadas tanto en tipo (servlets, APIs, entornos web, IDEs) como en alcance (almacenamiento, edición, entornos de desarrollo, razonamiento, conversores, lenguajes de consulta). Nosotros para implementar nuestro sistema, empleamos un conjunto estas herramientas. La elección de estas herramientas se hizo mediante una investigación de las características de las mismas. Dado el número de herramientas, la investigación se acoto por el alcance de la herramienta. A continuación, se describen algunas herramientas que exploramos, así como la herramienta elegida y la justificación de por qué se  eligió. 

%%%%%%%%%%%%%%
¿Qué herramientas necesitamos?
la lista de cosas que necesitamos
Estado del arte de herramientas
Por cada cosa, habrá que poner qué herramientas existen
Cuál elegimos y por qué
1. Editor de ontologías.
para las TBoxes de las ontologías
2. Editor de descripciones semánticas
para las ABoxes
necesita un "anotador"? existe? cuales hay ? hay que hacerlo? etc
más bien, nos fuimos por esta alternativa, puesto que las personas que nos van a ayudar (nos ayudaron?) con eso no necesariamente manejaban Protégé
3. Triplestore con cierto soporte de razonamiento
ventajas tiene qué es un triplestore? cuales hay ?
para las consultas muchas veces, los triplestores soportan cierto grado de razonamiento
como Jena mismo esa es una pregunta que habrá que investigarse
Sesame RDF, Stardog, Apache Jena, Virtuoso
Un razonador para que nos serviría en el proyecto?  lo necesitamos realmente? que ganamos que perdemos?
%%%%%%%%%%%%%%

A partir de la arquitectura del sistema SIR y de las tecnologías semánticas. Nosotros hicimos un análisis de las herramientas semánticas, para facilitar la construcción y desarrollo de este sistema SIR. Las tecnologías semánticas son variadas tanto en tipo (servlets, APIs, entornos web, IDEs) como en alcance (almacenamiento, edición, entornos de desarrollo, razonamiento, conversores, lenguajes de consulta). Dado el gran número de herramientas, la investigación se acoto por el alcance de la herramienta. A continuación, se describen algunas herramientas que exploramos, así como la herramienta elegida y la justificación de por qué se  eligió.

En un estudio sobre las herramientas para el manejo y la manipulación de ontologías [12] se analizaron Prolog Server Pages y Prosper, se evaluó el paquete RAP, que integra numerosas características, entre ellas se distinguen,  un motor de consulta en SPARQL [13], un servidor en RDF, y métodos específicos de vocabulario que permite la manipulación de modelos RDF.

Como se puede notar, el concepto de sentencia RDF es simple y no tiene gran complejidad, pero si se quiere escribir una anotación semántica, se debe estar familiarizado con la sintaxis RDF/XML [13]. Pero elaborar todas estas anotaciones manuales quita tiempo a los usuarios o miembros de la organización, además de que estas anotaciones tienen que ser validadas [14]  para que no tengan errores sintácticos o descriptivos, aunado a esto se tiene el problema de que los usuarios requieren aprender la sintaxis RDF/XML solo para anotar sus documentos, lo que se convierte en una tarea.

es necesario tener una herramienta que permita la elaboración de anotaciones semánticas, generando automáticamente con código RDF. En este punto se puede pensar en elaborar una herramienta que permita hacer las anotaciones, pero esta actividad requiere de mucho tiempo por tal razón se opto en llevar acabo una revisión documental y un análisis técnico de las herramientas de anotación semántica que actualmente están en uso y que facilitan está tarea.

Muchos de los recursos en la memoria corporativa son heterogéneos en formato, de tal manera se requiere que las herramientas de anotaciones semánticas puedan soportar los más formatos más comunes, como son PDF, documentos de procesadores de palabras 

Lo más importante de una herramienta de anotación es que sea libre. Porque aunque una herramienta posea todas las características si esta es de pago, va ser difícil tener varias licencias para los miembros de la organización. Al usar un sistema de licencia libre este se puede distribuir en la organización y de esta manera no se hace un gasto extra.

La finalidad de los sistemas de anotación semántica es proveer a los usuarios de una interfaz fácil y sencilla de usar, pero muchas veces se requiere más que la intuición para llevar acabo las anotaciones o hacer actividades más complicadas (entrenamiento y generación automática de anotaciones). Por está razón, es necesario contar con suficiente documentación, donde describa el uso del sistema, emplee  ejemplos y detalle las otras operaciones que se pueden llevar acabo como el entrenamiento y la generación automática de anotaciones.
Si el sistema de anotaciones es de software libre y se permite modificar los códigos del mismo. Entonces es deseable contar con documentos o manuales técnicos que detallen el funcionamiento del sistema, describiendo el funcionamiento de cada código y las operaciones intermedias. De ser posible en esta documentación se debe tener diagramas y figuras detalladas.

% TABLA ANOTACIONES en: C:\Users\Gatito\Dropbox\Gestión Semántica\Actividades 12P\Semana 10\tabla anotaciones.docx

Elección de la herramienta
Muchas de las herramientas que fueron analizadas tienen un gran potencial para generar anotaciones basadas en grandes cantidades de relaciones entre conceptos, pero este enfoque no es el ideal para la nuestra generación de anotaciones, ya que a mayor complejidad menor será el interés del usuario hacer anotaciones. Este enfoque basado en la generación de muchas relaciones es empleado por OntOMat Annoticer, AKTive media y GATE.
Por otro lado una herramienta como Amaya, no emplea relaciones sino que deja a la libertad del usuario insertar anotaciones en los recursos (más específicamente páginas web), pero está libertad no es deseable ya que se requiere tener cierto grado de orden. Aunque una gran ventaja de emplear Amaya, es permitir anotaciones colaborativamente.
Entonces para seleccionar una herramienta que permita la generación de anotaciones empleando una ontología de base, y que las relaciones entre conceptos sean limitadas a manera de ficha o formulario, se tiene una opción y está es MnM.
Pero porque no usar KIM si permite la automatización de anotaciones y la razón más importante es: las anotaciones generadas por KIM no son libres de ambigüedad ya que al anotar un documento referente a las pizzas, el concepto de pizza es empleado como ciudad y no como alimento. Por consiguiente es necesaria la supervisión humana, para saber si las anotaciones sugeridas son las correctas.
No solamente MnM fue elegida como herramienta por satisfacer las dos características antes mencionadas, además MnM genera códigos limpios y sin ataduras al etiquetado de propietario como es el caso de OntOMat. Además la ontología que emplea es basada en RDFS, que si bien no es muy rica en semántica como la OWL, permite restringir las propiedades (generadas a partir de relaciones RDF) que puede llenar el usuario. 
MnM es una herramienta que emplea Apache Ant, por lo cual se puede modificar desde el principio varios aspectos de configuración, además si se requiere hacer una configuración más especializada MnM proporciona los códigos fuentes. Como casi todas las herramientas, MnM permite la visualización de conceptos y de las relaciones empleando un navegador de ontología, y para visualizar los documentos tiene un API navegación web, que también permite la visualización de archivos locales basados en texto plano.
Pero a pesar de ser buena herramienta, también tiene algunas dificultades y deficiencias respecto a las características requeridas. Para el caso de emplear múltiples ontologías está herramienta no soporta esta característica, al igual que la colaboración entre los usuarios para una misma anotación. Si bien la herramienta soporta archivos basados en texto plano y en etiquetas, lo ideal fuera soportar los formatos más convencionales, por ejemplo, doc, pdf, ppt, odp, xls, video, imágenes, etc. Aunque esta herramienta es buena lamentablemente no hay suficiente documentación técnica, aunque en distintos artículos es mencionada.
Respecto a al automatización de MnM no se exploro teóricamente esta característica, pero de lo leído en artículos y manuales, para la generación automática de anotaciones se emplea un modulo llamado AMILCARE [27], pero es necesario que el usuario haga un de entrenamiento empleando un conjunto de documentos. Para ello es necesario encontrar páginas que tengan un formato estándar y describan lo mejor que se pueda nuestros recursos.

A.	Editor de ontologías (TBox y ABox)
Un editor de ontología es una aplicación que permite la generación de código en lenguajes ontológicos (como OWL) a partir de las instrucciones de un usuario. Algunos editores son en entornos de desarrollo integrados (IDE) que integran varias APIs. Estos IDEs permiten a partir de modelos gráficos (diseñados por los usuarios) construir ontologías en distintos tipos de sintaxis (turtle, RDF/XML, OWL/RDF, latex). 
1)	Protégé
?Esta plataforma es de código abierto que proporciona un conjunto de herramientas para la construcción de modelos de dominio y aplicaciones basadas en el conocimiento con ontologías. Protégé implementa un amplio conjunto de estructuras para modelar el conocimiento y operaciones que apoyan la creación, visualización y manipulación de ontologías en diversos formatos de representación. La interfaz de protégé es amigable para la creación de modelos de conocimientos y la introducción de datos. Protégé tienen una arquitectura que se basa en plug-in?s y API?s que amplían la funcionalidad de la plataforma. La plataforma Protégé soporta dos formas de modelar ontologías: 1) El editor de Frames permite a los usuarios construir y poblar ontologías que se basan en Frames. 2) El editor OWL permite a los usuarios construir ontologías en el Lenguaje Web Ontológico (OWL)? [9][11]. La herramienta perite exportar ontologías a una variedad de formatos, incluyendo RDF (S), OWL y XML Schema. 
2)	pOWL
9PHP, disponible en: http://php.net/
10Apache HTTP, disponible en: http://httpd.apache.org/
11Java Language, disponible en: http://docs.oracle.com/javase/specs/
12Apache Tomcat, disponible en: http://tomcat.apache.org/
 ?Esta herramienta es una solución para la edición de ontologías vía Web. El objetivo de POWL es ofrecer una herramienta fácil de implementar y fácil de usar que proporciona una solución escalable en la gestión de ontologías. La aplicación soporta la visualización, edición de ontologías RDFS y OWL, generación de consultas  RDQL, búsqueda de texto completo para los literales y los recursos, así como soporte para extensiones. Los modelos que se construyen con pOWL, se almacenan bases de datos relacionales y sólo las partes del modelo se carga en la memoria principal. Estos modelos de ontologías pueden ser importados a los siguientes tipos de sintaxis: XML, N3 y N-triples? [12].
3)	TopBraid 
?TopBraid es un entorno de modelado de clases para el desarrollo de ontologías OWL y la creación de aplicaciones semánticas. Esta herramienta ofrece un soporte completo para desarrollar, gestionar y probar configuraciones de los modelos de conocimiento e instancias de las bases de conocimiento. También esta herramienta  incorpora un framework  flexible y extensible con una API propietaria. Esta API sirve para el desarrollo de soluciones semánticas que permite integrar diferentes aplicaciones y fuentes de datos. Esta herramienta proporciona editores visuales para los grafos RDF y diagramas de clase. También proporciona la conversión automática de XML, XSD, hojas de cálculo, UML y otras fuentes de datos? [13]
4)	 SWOOP
?SWOOP es una herramienta para la creación, edición y depuración de ontologías OWL. Esta herramienta fue escrita en Java y es de código abierto. SWOOP proporciona un entorno integrado para crear y editar ontologías, comprobar si hay errores e inconsistencias (utilizando un razonador), navegar por múltiples ontologías, compartir y reutilizar los datos existentes. El editor de la ontología se basa en un navegador Web, con la finalidad, de que esta herramienta sea amigable y eficaz para el usuario web promedio? [14]
5)	Editor seleccionado
La mayoría de estos editores son adecuados para la generación de ontologías, ya que posee interfaces de usuario fáciles de usar. Sin embargo, no todos son fáciles de manejar, o tienen documentación disponible. Afortunadamente, protégé es la herramienta que proporciona varios beneficios en el desarrollo de modelos conceptuales. A continuación se listan las razones de escoger esta herramienta. 1) La herramienta es fácil de instalar, 2) posee una interfaz amigable e intuitiva para el usuario, 3) existe mucha documentación, 4) existen tutoriales y video-tutoriales, 5) es fácil de extender gracias a los plug-in?s, 6) permite transformar ontologías a otros formatos, 7) acceso a ontologías remotas, 8) permite importar ontologías, 9) facilidad para crear axiomas, 10) permite añadir literales/instancias a las Propiedades de forma sencilla, 11) permite visualizar el grafo RDF, 12) permite el uso de razonadores para inferir nuevo conocimiento, 13) permite consultar valores de los triples con SPARQL, 14) permite hacer capturas de imágenes del grafo RDF, 15) permite el apoyo colaborativo de las ontologías, y finalmente 16) posee un amplia comunidad que desarrolla esta aplicación.


B.	Descriptores semánticos (ABox)
Un descriptor semántico es una aplicación que genera automáticamente descripciones semánticas de los recursos en formato canónico RDF. Típicamente un descriptor permite a un usuario, escribir valores o nombres de instancias de las aserciones de un determinado recurso. El objetivo de un descriptor es construir el ABox de una determinada ontología. 
1)	OntoMat
Esta herramienta es una Interfaz Gráfica de Usuario (GUI) que proporciona ?una manera interactiva de describir semánticamente los documentos Web, de texto plano y de lenguajes de marcado? [15][16][17]. La herramienta está conformada por un navegador de ontologías y un navegador de documentos. El objetivo del navegador web es  que el usuario visualice el texto de un documento, seleccione partes de texto y los asigne a una Propiedad Dato. Mientras, el navegador de ontología permite al usuario, explorar el árbol de clases y crear individuos de las mismas. Esta herramienta se ejecuta en cualquier plataforma que tenga una máquina virtual. Con respecto a los archivos de entrada/salida. La herramienta admite los siguientes lenguajes ontológicos: OWL y DAML+OIL. Mientras los archivos de salida son OWL, orque las descripciones semánticas se integran directamente al grafo de la ontología. Actualmente, no existe un enlace para descargar esta herramienta, además esta herramienta no tiene soporte.
2)	MnM
Esta herramienta proporciona apoyo automatizado y semi-automatizado, para la descripción de páginas web con contenido semántico [16][17]. MnM posee una Interfaz Gráfica de Usuario que integra un editor de ontología, navegador Web, un editor de instancias y de Propiedades. MnM proporciona APIs de código abierto, para tener acceso a los servidores de ontologías y para la integración de herramienta de extracción de información. La herramienta MnM soporta los siguientes lenguajes de ontologías: RDF, DAML+OIL y OCML. Mientras, los archivos de salida son: documentos canónicos RDF, específicamente en sintaxis RDF/XML. La herramienta fue desarrollada por el Knowledge Media Institute en la Open University. Actualmente la herramienta está fuera de servicio y no hay una versión actualizada de esta.
3)	GATE
13Cómo crear un formulario de Google, disponible en: http://support.google.com/drive/bin/answer.py?hl=es&answer=87809/
?Esta herramienta es una infraestructura para el desarrollo de componentes para el procesamiento del lenguaje humano y el procesamiento de texto. Las tareas comunes de estos procesamientos son: tratamiento de la voz, apoyo a las decisiones, minería web, extracción de información  y descripciones semánticas. GATE es un entorno de desarrollo integrado (IDE) que integra plugins para las tareas antes mencionadas. El entorno incluye un repositorio de búsqueda multi-paradigma. Este repositorio se utiliza para indexar y buscar sobre el texto, anotaciones, esquemas semánticos (TBox) y aserciones. GATE contiene al sistema de información ANNIE. Este sistema permite describir cualquier tipo documento de texto automáticamente. Las descripciones se almacenan en formato DAML+OIL. Finalmente, GATE fue desarrollado por el grupo de Procesamiento de Lenguaje Natural de la universidad  de Sheffield? [18].
4)	Aktive Media
?Aktive Media es un mecanismo de descripción para un contexto específico. Esta herramienta es un sistema para la descripción automática de recursos multimedia. El objetivo de Aktive Media es automatizar el proceso de descripción, mediante el intercambio y la reutilización de conocimiento. Aktive Media proporcionar una interfaz que guía al usuario a través del proceso de descripción de los recursos y reduciendo la complejidad de esta tarea. Esta herramienta utiliza una ontología y almacena descripciones previas para ayudar al usuario? [17][19]
5)	Elección elegida
Muchas de las herramientas antes descritas, tienen el objetivo de generar descripciones semánticas en forma canónica RDF. Sin embargo, ninguna de estas herramientas es útil para crear el ABox (aserciones) de nuestra ontología. A continuación se listan los motivos de la anterior decisión. 1) No hay una versión estable de algunas herramientas, 2) También no hay soporte y documentación disponible, 3) La instalación requiere instalar otras tecnologías (apache ant o Java Development Kit), 4) Los lenguaje ontológico que soportan las herramientas, están descontinuados o son poco habituales, 5) los archivos de salida son en formato propio de la herramienta, 6) la recuperación de las descripciones son difíciles para los usuarios, 7) los usuarios que describen los documentos, requieren conocimientos previos de los elementos semánticos, 8) los usuarios también requieren más tiempo, para aprender adecuadamente el funcionamiento de la herramienta (GATE)y finalmente 9) La complejidad en la construcción del grafo semántico.
A partir de las anteriores limitantes, nosotros optamos por combinar formularios (Google Form13) y scripts para construir las descripciones semánticas. El objetivo de los formularios es captar/almacenar los metadatos de los recursos. Mientras, los scripts mapean estos metadatos a descripciones semánticas de los recursos. El funcionamiento detallado de formularios y scripts es el siguiente. Los diseñadores a partir de las Propiedades Objeto y Dato construyen un conjunto de formularios. Los formularios terminados se envían a un grupo de personas. Estas personas capturan los metadatos significativos de los recursos y los envían a un servidor. Estos metadatos se almacenen en una hoja de cálculo. Después de almacenar los metadatos de varios recursos, la hoja de cálculo se descarga como texto plano separado por comas (csv). Cada fila del archivo csv, se traduce en un conjunto de aserciones de un recurso. Estas aserciones se almacenan en un archivo canónico RDF (descripción semántica). Finalmente, para cada fila de cada archivo csv se generan un conjunto de descripciones semánticas.

C.	Triplestore

Triplestore
Todas las aserciones del ABox y axiomas del TBox deben ser almacenadas de forma permanente, con la finalidad de hacer futuras consultas sobre estos triples. El triplestore es el mecanismo que nos permite gestionar (almacenamiento y búsqueda) los triples. Un triplestore robusto de permitir el almacenamiento nativo de triples, carga y procesamiento del grafo RDF en memoria, consultar los valores de los triples y hacer inferencias a partir de los axiomas. 

Un triplestore es un framework para el almacenamiento y consulta de tripletas RDF. Este triplestore se considera un Sistema Gestor de Base de Datos para datos modelados en RDF. Típicamente, un triplestore emplea el estándar SPARQL como mecanismo para la consulta de datos. Algunos triplestore proporcionan la capacidad de inferir. Esta inferencia se hace a partir de los axiomas de un TBox. Con la  finalidad de que los resultados de las consultas en SPARQL sean más amplios [20].
1)	Apache Jena
?Esta herramienta es un framework para el desarrollo de aplicaciones Web Semánticas. Jena proporciona un conjunto de herramientas y librerías de Java, para el desarrollo de aplicaciones semánticas, herramientas y servlet. Este framework incluye los siguientes componentes. 1) Una API para la lectura, procesamiento y escritura de datos RDF en los formatos XMl, N-triples y turtle. 2) Una API para el manejo de ontologías OWL y RDFS. 3) Un motor de inferencia basado en reglas, para el razonamiento  de axiomas OWL y RDFS. 4) Store para el almacenamiento eficiente de triples RDF en el disco. 5) Un motor de consultas SPARQL. Finalmente 6) Servidores que permiten la publicación de datos RDF en otras aplicaciones? [21].
2)	Stardog
?La herramienta es rápida, ligera y comercial base de datos RDF para aplicaciones de misión crítica. El propósito de stardog es ejecutar consultas rápidas de datos RDF que están bajo su gestión. Stardog soporta: el lenguaje estándar SPARQL, los protocolos HTTP  y SNARL para acceso y control remoto, el modelo de datos RDF y para la inferencia y análisis de datos el lenguaje OWL 2. La carga de los datos en stardog es al momento de crear la Base de Datos. Stardog es estricto en el parsing de datos, por ejemplo, se requiere que las literales RDF coincidan explícitamente con sus tipos de datos, también los URI deben estar bien formados. Stardog permite esportar los datos RDF a diferentes formatos, como N-triples, RDF/XML, turtle o trig. Respecto a la búsqueda, stardog proporciona la capacidad de búsquedas semánticas. En esta búsqueda semántica se indexan literales RDF. Esta indexación crea una ?búsqueda de documentos? por literal RDF. Donde cada documento tiene los siguientes campos: ID literal, valor literal, y contextos. A partir de este índice, se consultan las literales para la recuperación de la información. Stardog para esta búsqueda se apoya Lucene que es un motor de búsqueda de texto? [22].
3)	4store
?4store es un almacén y motor de consulta de datos RDF. Las principales fortalezas de esta herramienta, son el rendimiento, seguridad, escalabilidad, y estabilidad. La herramienta corre en máquinas con Sistemas Operativos basados en UNIX y posee una licencia GNU General Public Licence, version 3. Lamentablemente, 4store no proporciona otras características más allá del almacenamiento de RDF y de las consultas SPARQL? [23].
4)	OWLIM
?OWLIM es una familia de repositorios semánticos, también conocidos como sistemas de gestión de bases de datos RDF. Estos repositorios tienen las siguientes características: 1) Motores RDF nativos que se han implementado en Java, 2) alto desempeño a través de Jena y Sesame, 3) soporte robusto para la semántica de RDFS,  OWL 2 RL y OWL 2 QL, 4) mejor escalabilidad, carga y rendimiento de consultas multiusuario, finalmente 5) uso de inferencia no trivial? [24].
5)	Sesame
?Este es un marco estándar de facto para el procesamiento de datos RDF. Este procesamiento tiene las siguientes actividades: analizar, almacenar, inferir y consulta sobre estos datos con SPARQL. Sesame incluye una API que puede ser conectada a una variedad de sistemas de almacenamiento (bases de datos relacionales en memoria, sistemas de archivos, indizadores de palabras clave, etc). Esta herramienta utiliza una API para el acceso local/remoto a los repositorios RDF. Finalmente, Sesame soporta los principales formatos RDF, como RDF/XML, Turtle, N-Triples, Trig y Trix? [25].

% TABLA ONTOLOGIAS en: C:\Users\Gatito\Dropbox\Gestión Semántica\Actividades 12P\Semana 10\doc auxiliar.docx
