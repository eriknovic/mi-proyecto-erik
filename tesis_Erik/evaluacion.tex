\chapter{Evaluación experimental}
\label{cap:exp}
%%%% Observación consiste en la medida y registro de hechos observables.
La \textit{integración semántica de los recursos} es el proceso de búsqueda y recuperación de información en un \textit{grafo de conocimiento (ontología)}. Un \textit{motor de búsqueda de tripletas} es el mecanismo encargado de realizar la consulta de información en los grafos de conocimiento, para responder una consulta dada. Este \textit{motor de tripletas} generalmente pertenece a un triplestore. En esta tesis, se emplea el \textit{triplestore Jena}. Éste proporciona dos componentes importantes: 1) \textit{un motor de búsqueda} para tripletas RDF, denominado \textbf{\textit{ARQ}} y 2) \textit{un motor de inferencia} que soporta los axiomas de nuestras ontologías, los cuales son descritos en la Sección \ref{sec:enrKrec}.

La \textit{calidad de los resultados} depende del uso o no de inferencia en nuestros modelo semántico. Si Jena emplea un \textit{modelo sin inferencia} como el ejemplo de la Figura \ref{fig:grafoSR}, entonces el motor ARQ puede proporcionar todos, varios o ningún resultado. Esta variedad en la entrega de resultados, depende de las consultas SPARQL: 1) \textit{consultas sobre las declaraciones de los recursos}, como la consulta de la Figura \ref{fig:q112rql}, 2) \textit{consultas que agrupan varios patrones para un criterio de búsqueda}, como las consultas de las Figuras \ref{fig:q2rqlSR} y \ref{fig:q2torqlSR}, y 3) \textit{consultas simplificadas}, como en las Figuras \ref{fig:q2rqlCR} y \ref{fig:q2torqlCR}. En contraste, Jena puede entregar mejores resultados cuando emplea un modelo que se obtiene de la inferencia en una ontología. Un ejemplo de este modelo se presenta en la Figura \ref{fig:grafoCR}.

Una característica asociada al uso de inferencia, es el impacto en el \textit{tiempo de procesamiento} para responder las consultas. Por un lado, se ha observado que este \textit{tiempo} es pequeño (menor a medio segundo) cuando se usa un \textit{modelo sin inferencia}. Mientras tanto, el \textit{tiempo para un modelo con inferencia} es mayor en comparación con con el tiempo del modelo sin inferencia.

%%%% Hipótesis es una solución para un problema dado.
Con base en estas observaciones, nuestras dos hipótesis de experimentación  son éstas:
\begin{enumerate}
\item \textit{El \textbf{triplestore Jena} obtiene \textbf{mejores resultados} cuando utiliza nuestros modelos con inferencia}.
\item \textit{El \textbf{tiempo de consulta} es \textbf{mayor} para nuestros \textit{modelos con inferencia} en comparación con nuestros \textbf{modelos sin inferencia}}.
\end{enumerate}

%%%% Método consiste en: la elección de los sujetos para confirmar la muestra, el procedimiento a seguir para éstos, las variables consideradas: dependiente, independiente y auxiliares.

%%Elaborar un experimento que ponga a prueba una hipótesis
Esta experimentación consiste en la realización de dos actividades para probar nuestras hipótesis de experimentación. \textit{La \textbf{primera actividad} es \textbf{evaluar la calidad de los resultados} para los modelos con y sin inferencia}. Esta evaluación consiste en estas etapas: 1) establecer una serie de consultas para interrogar nuestros modelos, 2) encontrar manualmente cuántos y cuáles recursos responden las consultas, 3) ejecutar las consultas con el motor ARQ de Jena y 4) comparar los recursos dados por Jena con las respuestas manuales.

\textit{La \textbf{segunda actividad} consiste en medir los \textbf{tiempos promedio de procesamiento} para las consultas de la primera actividad}. La finalidad de esta segunda actividad es comparar los tiempos de procesamiento para un modelo con inferencia y otro que no emplea ésta. La determinación del tiempo para modelos sin inferencia, consiste en medir los tiempos de: 1) \textit{ejecución de la consulta en en el modelo} y 2) \textit{recuperación de la información}. De la misma manera, la medición de tiempos para un modelo con inferencia es parecida a la medición en un modelos sin inferencia. La excepción es que en un modelo con inferencia, se toman en cuenta los tiempos para: \textit{el proceso de inferencia en el modelo} y \textit{la ejecución de la consulta al modelo inferido}.

En esta tesis, el proceso de \textit{integración semántica} está asociado a dos \textit{casos de uso} (cartografía de competencias y búsqueda de recursos digitales). Ahora bien, nuestra experimentación consiste en probar la \textit{calidad de los resultados} y el \textit{tiempo de procesamiento} para la \textit{integración semántica de recursos} en la \textit{memoria corporativa} del área de Redes y Telecomunicaciones. Por esta razón, las dos actividades de nuestra experimentación deben ser aplicadas a nuestros dos \textit{casos de uso}.

%%Elección de los sujetos para confirmar la muestra
Los sujetos de nuestra experimentación son un conjunto de personas, documentos y archivos multimedia que son generados artificialmente. Esta \textit{generación artificial} consiste en el uso de scripts para: 1) \textit{asignar un identificador URI para un conjunto de \textbf{recursos de información ficticios}} y 2) \textit{generar tripletas RDF para estos recursos con base en las \textbf{propiedades} y \textbf{clases} de nuestras ontologías, así como \textbf{datos aleatorios}}. 

Un script genera un conjunto de declaraciones para los recursos persona. Mientras, otro script genera las declaraciones para los documentos y archivo multimedia. El algoritmo \ref{alg:fsg} presenta el funcionamiento general de ambos scripts para la generación y almacenamiento de tripletas RDF.

\begin{algorithm}
\SetKwData{Sigma}{$\sigma_i$}
\SetKwData{Model}{$modelo_{rdf}$}
$N\leftarrow$  número de \textit{recursos ficticios de información} a describir\;
\Model$\leftarrow$Crear un modelo rdf\;
\For{$i\leftarrow 1$ \KwTo $N$}{
	\Sigma$\leftarrow$Crear el recurso $i$ y establecer un identificador URI para éste\;
	Elaborar los valores para cada característica significativa de este recurso (\Sigma)\; \label{lin:values}
	Escribir las aserciones, concatenando el URI del recurso (\Sigma), las propiedades de la ontología y los valores del paso \ref{lin:values}\;
}
Guardar el \Model en un archivo con extensión ``\textit{rdf}'' y sintaxis de serialización \textit{Turtle}\;
\caption{Funcionamiento básico de scripts para la generación de tripletas artificialmente}
\label{alg:fsg} 
\end{algorithm}

El apéndice \ref{aped:AlgDS} presenta los dos algoritmos con el funcionamiento detallado de los scripts. Un algoritmo para los datos simulados de los recursos persona y el otro para los recursos digitales.

La finalidad del uso de \textit{información simulada} es tener rápidamente un volumen grande de datos en nuestros ABox. La \textit{cantidad de información} en estos ABox debe ser realista con respecto al área de Redes y Telecomunicaciones (RyT). Ya que al tener información realista, nuestra experimentación se ajusta a la cantidad de datos que esperamos manejar en la integración semántica. Otra razón del uso de información simulada es ver si Jena soporta esta escala realista de datos (según los profesores del área RyT).

Las cantidades de \textit{recursos persona} son 60 recursos artificiales y 13 recursos reales, dando un total de 73 personas. Mientras, las cantidades para los \textit{recursos digitales} son 16 recursos reales y 1314 recurso simulados, un total de 1330 recursos digitales.

En nuestra experimentación, algunos \textit{recursos persona} tienen la declaración que los asignan explícitamente a una de estas clases: \textit{Estudiante (sirp:Student)}, \textit{Empleado (sird:Emplyee)} y \textit{Profesor (sirp:Teacher)}. Otros recursos persona carecen de esta asignación, pero con inferencia éstos pueden clasificarse en una o varias clases de la \textit{ontología cartografía de competencias}.

En concreto, se tienen estas \textit{cantidades de recursos} por clase: 51 recursos son profesionistas y 23 son \textit{estudiantes}. Los 51 recursos persona mediante inferencia son asignados a la clase \textit{Profesionista (sirp:Professional)}. De estos 51 profesionistas se tiene que 19 son profesores y 9 son empleados. Por otro lado, de los 23 estudiantes se tiene que 9 recursos están asignados a la clase \textit{Estudiante} y los 14 restantes por inferencia son asignados a la clase \textit{Estudiante}. Existen 13 recursos persona que mediante inferencia se clasifican en la clase \textit{Investigador (sirp:Researcher)}.

La Tabla \ref{tab:noRP} muestra las cantidades de \textit{recursos persona} por clases de la \textit{ontología cartografía de competencias}. La \textit{primera columna} presenta el nombre de las clases, la \textit{segunda} el número de recursos que tienen la declaración que los asigna explícitamente a una clase y la \textit{tercera columna} el número de recursos que por inferencia tienen la declaración para asignarlos a una clase.

\begin{table}[!htb]
\renewcommand{\arraystretch}{1.2}
\centering
\begin{tabular}{| >{\centering\arraybackslash}m{2in} | >{\centering\arraybackslash}m{1.5in} | >{\centering\arraybackslash}m{1.5in} | }
\hline 
\multirow{2}{*}{\textbf{Clase}} & \multicolumn{2}{c|}{\textbf{Número de Recursos}} \\
\cline{2-3} 
 & \textbf{Asignación explícita} & \textbf{Asignación explícita y con inferencia}\\
\hline 
\hline
Persona & 0 & 73\\
\hline
Investigador & 0 & 13\\
\hline
Profesionista & 0 & 51\\
\hline
Estudiante & 11 & 23\\
\hline
Profesor & 19 & 19\\
\hline
Empleado & 9 & 9\\
\hline
\end{tabular}
\caption{Número de recursos persona por clase.}
\label{tab:noRP}
\end{table}

De la misma manera que los \textit{recursos persona}, algunos \textit{recursos digitales} tienen la declaración que los asignan explícitamente a una clase. Otros recursos carecen de esta asignación, pero con inferencia éstos pueden clasificarse en una o varias clases de la \textit{ontología búsqueda de recursos digitales}.

Los 1330 recursos digitales de nuestra experimentación se clasifican en: 156 artículos, 366 libros, 34 reportes técnicos, 146 páginas web, 73 tesis, 42 videos, 42 audios, 77 imágenes y 112 presentaciones. De los 156 artículos, 89 recursos tienen la declaración explícita a la clase \textit{Artículo (sird:Paper)} y los restantes 67 mediante inferencia tienen la declaración a esta clase. En los libros, 185 recursos tienen la declaración explicita y 181 recursos mediante inferencia tienen la declaración a la clase \textit{Libro (sird:Book)}. De la misma manera, 79 recursos tienen la declaración explicita a la clase \textit{Página Web (sird:PageWeb)} y 31 recursos a la clase \textit{Tesis (sird:Thesis)}. Mientras, 67 recursos mediante inferencia pertenecen a la clase  \textit{Página Web} y 42 a la clase \textit{Tesis}. Por ultimo, los 1330 recursos se clasifican en 815 \textit{Documnetos (sird:Document)} y 515 \textit{Multimedia (sird:Multimedia)}. Las declaraciones a estas dos clases se obtienen mediante inferencia.

La Tabla \ref{tab:noRD} presenta las cantidades de recursos digitales por clases de la \textit{ontología recursos digitales}. Esta Tabla \ref{tab:noRD} presenta la misma estructura de la Tabla \ref{tab:noRP} 

\begin{table}[!htb]
\renewcommand{\arraystretch}{1.2}
\centering
\begin{tabular}{| >{\centering\arraybackslash}m{2in} | >{\centering\arraybackslash}m{1.5in} | >{\centering\arraybackslash}m{1.5in} | }
\hline 
\multirow{2}{*}{\textbf{Clase}} & \multicolumn{2}{c|}{\textbf{Número de Recursos}} \\
\cline{2-3} 
 & \textbf{Asignación explícita} & \textbf{Asignación explícita y con inferencia}\\
\hline 
\hline
Recurso Digital & 0 & 1330\\
\hline
Documento & 0 & 815\\
\hline
Artículo & 89 & 156\\
\hline
Reporte Técnico & 34 & 34\\
\hline
Página Web & 79 & 146\\
\hline
Tesis & 31 & 73\\
\hline
Libro & 185 & 366\\
\hline
Multimedia & 0 & 515\\
\hline
Presentación & 112 & 112\\
\hline
Audio & 42 & 42\\
\hline
Vídeo & 42 & 42\\
\hline
Imagen & 77 & 77\\
\hline
\end{tabular}
\caption{Número de recursos digitales por clase.}
\label{tab:noRD}
\end{table}

El siguiente paso en esta experimentación es tener un conjunto base de consultas, así como saber cuántos y cuáles recursos de nuestras ontologías responden a estas consultas. Para elegir estas consultas, se retomaron las consultas asociadas a las preguntas de la Sección \ref{sec:byrKrec}. Con base en estas consultas se encontraron los recursos que responden éstas.

La Tabla \ref{tab:qrynoRP} muestra las preguntas base para la \textit{cartografía de competencias}. En esta Tabla, la primera columna presenta el identificador para cada una de las diecinueve pregunta, la segunda columna enuncia la pregunta y la tercer columna presenta el número de recursos que responden a ésta. De la misma manera, la Tabla \ref{tab:qrynoRD} presenta un identificador, las preguntas y cantidad de recursos que responden a éstas, para la \textit{búsqueda de recursos digitales}.

\begin{table}[!htb]
%\renewcommand{\arraystretch}{1.2}
\centering
\begin{tabular}{>{\centering\arraybackslash}m{1in} >{\arraybackslash}m{3.5in} >{\centering\arraybackslash}m{1in}}
\hline 
Id. & Pregunta & No. de Recursos\\
\hline
\hline 
Q1.1 &  ¿Cuáles el nombre, correo, sitio web, género y edad de las personas del área de RyT? & 73 \\
\hline
Q1.2 & ¿Cuál es el nombre, sitio web y el lugar donde laboran las personas del RyT? & 73\\
\hline 
Q1.3 & ¿Quiénes son mayores de 20 años y menores de 45 años? & 50\\
\hline 
Q1.4 & ¿Quiénes son profesionistas del área de RyT? & 51\\
\hline 
Q1.5 & ¿Quiénes trabajan en la Clark \& Parsia y son del sexo Masculino? & 3\\
\hline 
Q1.6 & ¿Quiénes son estudiantes y leen en inglés? & 8\\
\hline 
Q1.7 & ¿Quienes hablan, leen y escriben en inglés? & 16\\
\hline 
Q1.8 & ¿Qué estudiantes saben algo de inglés? & 6\\
\hline 
Q1.9 & ¿Qué profesores tienen la capacidad de síntesis? & 2\\
\hline 
Q1.10 & ¿Qué profesionistas tienen conocimiento en los temas de Web Semántica? & 58\\
\hline
Q1.11 & ¿Qué profesores tienen conocimientos en Sistemas Distribuidos? & 3\\
\hline 
Q1.12 & ¿Quiénes tienen conocimiento en Java, OWL, RDF, Threads, C, OpenMP? & 1\\
\hline 
Q1.13 & ¿Qué estudiantes tienen algún conocimiento en los subtemas de Sistemas Operativos? & 33\\
\hline 
Q1.14 & ¿Quiénes trabajan en una Universidad? & 24\\
\hline 
Q1.15 & ¿Quienes laboran en la UAM y tienen algún conocimiento en  Web Semántica? & 19\\
\hline 
Q1.16 & ¿Qué personas tienen como asesor a Carolina Medina? & 2\\
\hline 
Q1.17 & ¿Quiénes son los colegas de Ricardo Marcelin? & 8\\
\hline 
Q1.18 &  ¿Quiénes conocen a Carolina Medina Ramirez? & 11\\
\hline 
Q1.19 & ¿Qué personas son profesores-investigadores? & 9\\
\hline 
\end{tabular}
\caption{Preguntas y cantidad de personas que responden a éstas.}
\label{tab:qrynoRP}
\end{table}

\begin{table}[!htb]
%\renewcommand{\arraystretch}{1.2}
\centering
\begin{tabular}{>{\centering\arraybackslash}m{1in} >{\arraybackslash}m{3.5in} >{\centering\arraybackslash}m{1in}}
\hline 
Id. & Pregunta & No. de Recursos\\
\hline
\hline 
Q2.1 & ¿Cuáles son los títulos, rutas, extensión, idioma de todos los recursos digitales de RyT? & 1330 \\
\hline
Q2.2 & ¿Cuáles libros tratan sobre algunos temas de Sistemas Distribuidos? & 103\\
\hline 
Q2.3 & ¿Qué recursos fueron publicados por la UAM? & 18\\
\hline 
Q2.4 & ¿Qué documentos son para dar un curso de Sistemas P2P? & 31\\
\hline 
Q2.5 & ¿Qué recursos multimedia son mayores al año 2009? & 119\\
\hline 
Q2.6 & ¿Cuáles documentos tratan sobre Ontologías? & 30\\
\hline 
Q2.7 & ¿Qué recursos fueron publicados en una Revista científica? & 156\\
\hline 
Q2.8 & ¿Qué recursos tienen en su contenido las palabras "linked data"? & 159\\
\hline 
Q2.9 & ¿Cuáles documentos en inglés y mayores al año 2000 son de autoría de Erik Alarcón Zamora? & 2\\
\hline 
Q2.10 & ¿Cuáles la tesis de Samuel Hernández Maza? & 4\\
\hline 
\end{tabular}
\caption{Preguntas y cantidad de recursos digitales que responden a éstas.}
\label{tab:qrynoRD}
\end{table}


----> Aquí voy


Para evaluar este costo en tiempo, calculamos el tiempo promedio que tarda cada consulta en responderse. Específicamente, nosotros tomamos el tiempo desde que se consulta la información del modelo hasta que se presentan los resultados en pantalla. Esta operación la repetimos veinte veces por consulta, de esta manera, sacamos el tiempo promedio por consulta de nuestro modelo. 

Esta medición del tiempo promedio se hace a partir de un script en Java. Este script se ejecuta en una computadora que tiene un procesador Intel core I7 a 2.3GHz con 8Gb en ram y 8 núcleos de procesamiento.  Las siguientes dos tablas presentan los tiempos de respuesta para nuestro conjunto de consultas. En la tabla 7 se muestran los valores de las consultas para el caso de uso Cartografía de Competencias, en tanto, la tabla 8 muestra los tiempos para el caso de uso Recursos Digitales. En ambas tablas, se contemplan los tiempos de respuesta y el número de resultados para las consultas que emplean sólo con ABox, así como para las consultas que utilizan ABox, TBox y un Razonador (ATR).

--------------
Para los recursos persona en esta experimentación se tienen 1750 triples. Mientras, para los recursos digitales se tienen 20429 triples. De esta manera, el número total de triples en esta experimentación son 22179.

Por otro lado, basándonos en las consultas básicas para nuestros modelos, el análisis de los triples escritos manualmente y el uso de variables contador en los dos scripts, se identificaron para cada consulta el número de recursos que responden a la misma. En la tabla 3 se listan solamente 10 de nuestras 28 preguntas y el número de resultados de las mismas.
--------------
%%Procedimiento a seguir para éstos

Ahora bien, la finalidad de este listado es tomar los tiempos promedios y el número de respuestas, cuándo las consultas SPARQL se hacen con el motor sin razonador y con razonador. Con la finalidad de averiguar la precisión [5], así como el desempeño del motor de SPARQL y el razonador de Jena.

Las dos variables de experimentación son tiempo y número de resultados.  La variable tiempo nos permite sacar el tiempo promedio que toma una consulta en ser ejecutada K veces. Mientras la variable número de resultados almacena la cantidad de recursos que fueron recuperados para una consulta dada. 
	
Para encontrar los valores de estas variables, nosotros empleamos un programa en Java. Este programa se ha diseñado para ejecutar únicamente una consulta e imprimir los valores de las variables en pantalla. El programa permite elegir al usuario el modelo RDF a consultar. Si es modelo RDF con triples explícitos, entonces solo cargan los triples (ABox) de los recursos. Por el contrario, si el modelo es con triples inferidos, entonces se cargan los triples (ABox), los axiomas (TBox) y se hace inferencia con el razonador de Jena.
Este programa se ejecutó en una computadora con las siguientes capacidades: Procesador Intel Core I7 a 2.3GHz con 8Gb en RAM y 8 núcleos de procesamiento, y los valores resultantes de las variables se muestran en la Tabla 2.


%%Variables consideradas: dependiente, independiente y auxiliares


%%%% Resultados consiste en describir: cuales son las relaciones observadas entre las variables y la descripción gráfica de estos resultados.

---------------------------
En esta tabla se tienen dos columnas compuestas, la columna (titulada conocimiento explícito) muestra los valores de las consultas que emplearon únicamente el modelo con triples explícitos. Mientras, la segunda columna (titulada conocimiento inferido) muestra los valores de las consultas que emplearon el modelo con triples explícitos, axiomas y un razonador. Para las columnas sencillas, la columna ?Número de resultados? muestra el número de recursos recuperados del total esperado para la consulta dada, mientras la columna ?Tiempo promedio? muestra el tiempo promedio de consulta en milisegundos.

En algunos casos, la consulta al conocimiento explícito recupera todos los recursos esperados y los tiempos de respuesta son pequeños (no pasan del segundo). Sin embargo, en otras consultas se descartaron varios recursos que si responden la consulta. Esto se debe a que algunos recursos carecen un determinado triple. Por otro lado, las consultas al grafo con triples inferidos permitieron recuperar todos los recursos esperados, porque mediante los axiomas y el razonador se deducen triples (materializaron) que serán considerados por el motor de búsqueda . Sin embargo, el tiempo de procesamiento es mucho mayor porque se invierte tiempo en procesar e inferir relaciones en el grafo RDF.

Todo tiene un costo, cuando el razonador materializa los triples en el modelo, éste consume tiempo en procesamiento y al hacer una consulta, el motor debe comparar más aserciones. El desarrollador no debe abusar de la axiomatización, en algunos casos cuando la consulta es sobre  hechos explícitos, no es necesario el uso del razonador, basta con escribir y hacer la consulta sobre el conocimiento explícito.
---------------------------

%%%% Conclusiones, se obtienen a partir del estudio de los resultados. Éstas son el resultado de la discusión de las premisas.

La primer conclusión afirma que el performance mejora cuando se usan axiomas. Esta afirmación resulta cierta, porque un razonador deduce una relación que vincula directamente dos objetos. Análogamente, resulta más rápido ir por el camino directo que por una serie de rutas hasta el mismo objeto.

La segunda conclusión tiene que ver con el número de resultados. Si bien, las aserciones establecen un conjunto directo y estático de enlaces entre los distintos recursos de nuestro modelo. En muchas ocasiones, al momento de construir una consulta SPARQL no se contemplan algunos de estos enlaces, inclusive en otros casos, estos enlaces no están escritos explícitamente. Por consiguiente, mucho recursos no se contemplan como respuesta para una consulta. En contraste, los axiomas, aserciones y un razonador, establecen estos enlaces entre recursos de forma explícita en memoria, de esta manera, las consultas respondan más resultados que no se habían contemplado.

%http://hal-lirmm.ccsd.cnrs.fr/docs/00/63/97/05/PDF/A_Flexible_System_for_Ontology_Matching.pdf

%%Precisión
%%?Es la proporción del material recuperado que realmente es relevante, del total de documentos recuperados? [2, 3]. En donde la precisión está dada por la relación entre Documentos Relevantes Recuperados y Documentos recuperados. Y cuyo intervalo está entre el cero y uno.
%%Presisión =  (Documentos Relevantes Recuperados)/(Total de Documentos recuperados)
%%Dibujo de ejemplo
%%Exhaustividad
%%?Proporción de material relevante recuperado del total de documentos que son relevantes, Donde la exhaustividad es inversamente proporcional a la precisión? [3]. Igual que en la precisión el intervalo está entre el cero y uno.
%%Exhasutividad =  (Documentos Relevantes Recuperados)/(Total de Documentos Relevantes en la MC)

Funcionamiento de los scripts 
%https://docs.google.com/document/d/1c-JfQYGg7O2xMTNh5gCmdtiDf2vmrsreQfpLU9na4AQ/edit

\section{Escenarios de experimentación}
Algún texto...


\begin{table}[!htb]
\renewcommand{\arraystretch}{1.2}
\centering
\begin{tabular}{| >{\centering\arraybackslash}m{1in} | >{\centering\arraybackslash}m{1in} | >{\centering\arraybackslash}m{1in} | >{\centering\arraybackslash}m{1in} | >{\centering\arraybackslash}m{1in} | }
\hline 
\multirow{2}{*}{Id. Consulta} & \multicolumn{2}{c|}{Modelo (ABox)} & \multicolumn{2}{c|}{Modelo (Razonador+Ontología)}\\
\cline{2-5} 
 & Tiempo promedio (ms) & No. Recursos  & Tiempo promedio (ms) & No. Recursos\\
\hline 
\hline
Q1 & 12 & 1330/1330 & 138 & 1330/1330\\
\hline
Q2 & 10 & 0/103 & 194 & 103/103\\
\hline
Q3 & 8 & 18/18 & 406 & 18/18\\
\hline
Q4 & 28 & 15/31 & 129 & 31/31\\
\hline
Q5 & 7 & 66/119 & 157 & 119/119\\
\hline
Q6 & 9 & 15/30 & 4016 & 30/30\\
\hline
Q7 & 12 & 156/156 & 3520 & 156/156\\
\hline
Q8 & 16 & 159/159 & 3472 & 159/159\\
\hline
Q9 & 42 & 0/2 & 3451 & 2/2\\
\hline
Q10 & 13 & 3/4 & 3312 & 4/4\\
\hline
\end{tabular}
\end{table}

\section{Experimentación}
Más texto...

\section{Resultados}
Más texto...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
La integración semántica consiste en la búsqueda y recuperación de la información de los recursos. En este punto, es importante evaluar esa recuperación y medir los tiempos de procesamiento para un modelo con razonamiento en Jena. Para evaluar la recuperación de los recursos consiste en enumerar los recursos que responden a una consulta. Mientras, el tiempo promedio de procesamiento es la media en tiempo (milisegundos) que tarda una consulta en ejecutarse.
	En esta experimentación hay 73 personas y 1330 recursos digitales. Nosotros escribimos manualmente los triples de 11 personas que están adscritas al Departamento de Ingeniería Eléctrica de la Universidad Autónoma Metropolitana y los triples de las otras 60 fueron generados artificialmente. Por otro lado, nosotros escribimos manualmente los triples de 16 recursos digitales, mientras que los triples de los otros 1314 fueron generados artificialmente.
	Las 73 personas se clasifican en: Profesor, Estudiante, Empleado, Profesionista, Investigador y Persona. Mientras los 1330 recursos digitales se clasifican en: Artículos, Reportes Técnicos, Páginas Web, Tesis, Libros, Presentaciones, Imágenes, Audios, Videos, Documento, Multimedia y Recurso Digital. En particular, para cada clase de Persona y Recursos Digital se tienen las siguientes cantidades:
Para los recursos persona en esta experimentación se tienen 1750 triples. Mientras, para los recursos digitales se tienen 20429 triples. De esta manera, el número total de triples en esta experimentación son 22179.
	Por otro lado, basándonos en las consultas básicas para nuestros modelos, el análisis de los triples escritos manualmente y el uso de variables contador en los dos scripts, se identificaron para cada consulta el número de recursos que responden a la misma. En la tabla 3 se listan solamente 10 de nuestras 28 preguntas y el número de resultados de las mismas.
	Ahora bien, la finalidad de este listado es tomar los tiempos promedios y el número de respuestas, cuándo las consultas SPARQL se hacen con el motor sin razonador y con razonador. Con la finalidad de averiguar la precisión [5], así como el desempeño del motor de SPARQL y el razonador de Jena.
	Las dos variables de experimentación son tiempo y número de resultados.  La variable tiempo nos permite sacar el tiempo promedio que toma una consulta en ser ejecutada K veces. Mientras la variable número de resultados almacena la cantidad de recursos que fueron recuperados para una consulta dada. 
	Para encontrar los valores de estas variables, nosotros empleamos un programa en Java. Este programa se ha diseñado para ejecutar únicamente una consulta e imprimir los valores de las variables en pantalla. El programa permite elegir al usuario el modelo RDF a consultar. Si es modelo RDF con triples explícitos, entonces solo cargan los triples (ABox) de los recursos. Por el contrario, si el modelo es con triples inferidos, entonces se cargan los triples (ABox), los axiomas (TBox) y se hace inferencia con el razonador de Jena.
Este programa se ejecutó en una computadora con las siguientes capacidades: Procesador Intel Core I7 a 2.3GHz con 8Gb en RAM y 8 núcleos de procesamiento, y los valores resultantes de las variables se muestran en la Tabla 2.

Interpretación de resultados
	En esta tabla se tienen dos columnas compuestas, la columna (titulada conocimiento explícito) muestra los valores de las consultas que emplearon únicamente el modelo con triples explícitos. Mientras, la segunda columna (titulada conocimiento inferido) muestra los valores de las consultas que emplearon el modelo con triples explícitos, axiomas y un razonador. Para las columnas sencillas, la columna ?Número de resultados? muestra el número de recursos recuperados del total esperado para la consulta dada, mientras la columna ?Tiempo promedio? muestra el tiempo promedio de consulta en milisegundos.
	En algunos casos, la consulta al conocimiento explícito recupera todos los recursos esperados y los tiempos de respuesta son pequeños (no pasan del segundo). Sin embargo, en otras consultas se descartaron varios recursos que si responden la consulta. Esto se debe a que algunos recursos carecen un determinado triple. Por otro lado, las consultas al grafo con triples inferidos permitieron recuperar todos los recursos esperados, porque mediante los axiomas y el razonador se deducen triples (materializaron) que serán considerados por el motor de búsqueda . Sin embargo, el tiempo de procesamiento es mucho mayor porque se invierte tiempo en procesar e inferir relaciones en el grafo RDF.
Todo tiene un costo, cuando el razonador materializa los triples en el modelo, éste consume tiempo en procesamiento y al hacer una consulta, el motor debe comparar más aserciones. El desarrollador no debe abusar de la axiomatización, en algunos casos cuando la consulta es sobre  hechos explícitos, no es necesario el uso del razonador, basta con escribir y hacer la consulta sobre el conocimiento explícito.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Documento importante
%https://docs.google.com/document/d/1rv-RDqdSB3Sd_zd7WANHDRXqEa_UHgV0WjC0DupYK4M/edit
